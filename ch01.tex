\chapter{Preliminaries}

\section{Basic terminology}

There is a long history of interests in heritable characters.  In 1805, Gregor
Mendel discovered his laws of inheritance.  Later, Francis Galton and his
student Karl Pearson observed that family resemblance of many traits did not
show Mendelian patterns of inheritance, but that trait value of offspring
tended to be, on average, midway between the parents, with some variability.
In 1918, Ronald Fisher showed that continuous trait may be determined by small
effects of many genes.  By central limit theorem, a large number of such
effects would result in a normal distribution.  The concept of the gene was
finally materialised in 1953 by Watson and Crick who unveiled the duplex
structure of DNA (deoxyribonucleic acid).  Until early 1980s, the study of
association between genetic markers and human disorders was much limited by the
number of genetic markers available, but this has been rapidly changed by the
Human Genome Project, which has created an unprecedented opportunity and
multidisciplinary collaboration including biologists, medical doctors,
mathematicians and computer scientists.

The total amount of genetic information in individual possesses is called the
genome. Gene is the basic unit of inheritance.  Human genes are stored in 23
pairs of chromosomes -- 22 pairs of autosomes and 1 pair of sex chromosomes (XX
for females or XY for males) which are found in the cell nucleus.  The position
at a chromosome where a gene is located is called {\bf locus}.  A gene may have
two or more variant forms, each called {\bf allele}, and such a gene is called
biallelic or multiallelic.  An individual has two alleles (which may be the
same or different) for each gene, one on each of the two homologous
chromosomes, at the appropriate locus for that gene.  At the molecular level,
genes are specific DNA coding sequences.  There are approximately $3\times
10^9$ nucleotides in the human genome.  The lengths of human genes are variable
(Eyre-Walker \& Keightley 1999), and according to the estimate that a typical
genes is about 30,000 nucleotides long, these nucleotides form about
50,000$\sim$100,000 genes (Cantor 1994; Thompson 1996; Lange 1997; Ott 1999).
This estimate has been recently been refined to about 30,000. Although this
estimate is based on several sources, only some of them overlap (Hogenesch et
al.  2001).  In addition to nucleic DNA there is also mitochondrial DNA
(mtDNA).  The mitochondrion is a small haploid nonnucleic DNA organelle about
17,000 base pairs long, which is primarily maternally inherited.

A lot of current biomedical researches involves the characterisation of genes
and their functional roles, much of this research is possible due to
availability of {\bf genetic markers}, i.e., anonymous sequences of DNA that
shows polymorphic variation, such as restricted fragment-length polymorphism
(RFLP), simple sequence repeat (SSR), and single nucleotide polymorphism (SNP).
The {\bf human genome project} is a global effort towards understanding the
human genome and includes development of the following tools (Lander \&
Waterman 1995):  {\bf genetic maps}, to produce a genetic map showing the
location of 5,000 polymorphisms that can be used to trace inheritance of
diseases in families; {\bf physical maps}, to produce a collection of
overlapping pieces of DNA that cover all the human chromosomes; and {\bf DNA
sequence}, to sequence the entire genome.  In early 2001, the first complete
draft of human genome was produced.  As of October 2001, a total of 9,588 genes
or phenotypes had been established (Online Mendelian Inheritance in Man,
http://www.ncbi.nlm.nih.gov).

Simple traits such as cystic fibrosis, Huntington disease and diastrophic
dysplasia are controlled by a single gene and called {\bf monogenic}, as
compared to {\bf oligogenic} traits where several genes are involved.  Many
genes control some part of the developmental process, and are sometimes
referred to as `switch genes'.  The maternal and paternal alleles of an
individual at a locus define the {\bf genotype} of the individual at that
locus.  Alleles (at different loci) received from one parent are referred to as
{\bf haplotype}.  The {\bf phenotype} is an observable or measurable trait of
an individual.  The relationship between genotype and phenotype can be
characterised by {\bf penetrance}, the conditional probability of observing a
phenotype given a genotype.

Genetic analysis often involves {\bf pedigree}, which is a collection of
individuals who are genetically related.  Individuals in a pedigree are either
{\bf founders} whose parents are not in the pedigree or {\bf non-founders}
whose parents are in the pedigree.  A large pedigree may consist of many {\bf
nuclear families} each including parents and their offsprings (children).  {\bf
Mendel's first law} states that for any gene, each parent transmits one allele
chosen at random to its offspring.  {\bf Mendel's second law} declares that for
any two genes, the alleles transmitted by a parent are independent.  The
separation of the two members of a pair of alleles during the formation of
gametes is called {\bf segregation}, and is due to the separation of the two
homologous chromosomes during meiosis.  In fact, genes on the same chromosomes
tend to be inherited together, a phenomenon called {\bf linkage}, so the second
law generally turns out to be true only for non-syntenic loci.  In meiosis,
each member of a pair of homologous chromosomes replicates to form two sister
chromosomes known as chromatids.  The maternally and paternally derived
chromatids cross over to form chromosome of offspring.  {\bf Crossing-over} is
the reciprocal exchange of segments between non-sister chromatids during
meiosis.  A recombination is said to have occurred between two loci, if alleles
at those loci on a single offspring chromosome are of different grand-parental
origin.  {\bf Interference} is the lack of independence in recombinations at
different intervals on a chromosome.

The risk for developing many common diseases such as diabetes is influenced by
both genetic and environmental factors.  These diseases are called {\bf complex
traits} because of their complex aetiology (Lander \& Schork 1994).  Complexity
may take the form of:  {\bf incomplete penetrance}, the probability that
individuals inheriting the gene will have the disease phenotype may be less
than 1 and may depend on age or other factors; {\bf phenocopy}, a disease can
be due to nongenetic causes; {\bf genetic heterogeneity}, a disease may be due
to different genetic mutations in different individuals; and {\bf polygenic
inheritance}, the liability of disease is due to the additive or interactive
effects at multiple loci.  There are other phenomena such as {\bf imprinting},
the difference in function of an allele according to its parental origin.
Statistically, the term {\bf additive} refers to the accumulative effects of
individual alleles, {\bf dominance} refers to the interaction between alleles
at the same locus, and {\bf epistasis} refers to the interaction between
alleles at different loci.  {\bf Pleiotropic expression} is a situation in
which an allele has more than one distinct phenotypic effect.

Development of statistical and computational methods can be classified into two
broad categories:  the inference of underlying genetic mechanism assuming the
relationship structure of the observed individuals or population is known (in
both experimental and natural populations), and the inference of structure
assuming the underlying biological basis is known (usually human studies).  In
experiment where individuals of an organism can be chosen for breeding, design
is a major issue, and missing data are few.  In human genetic studies, problems
of missing data and sampling procedures are paramount (Thompson 1996).  While
the data necessary to understand different complex traits is disease-specific,
the underlying principles used to identify and dissect the genetic component
are applicable to a variety of diseases.  The {\bf positional cloning} approach
is to map and identify previously unknown loci, which involves two initial
types of studies.  First, a disease model is developed to approximate the mode
of inheritance of the disease.  Second, one or more of the relevant genes is
localised (mapped) to a chromosomal region by a systematic screening of the
whole genome.  The {\bf candidate gene} approach is to study loci which are
suspected to play a key role in the disease.  There are two major difficulties
in genetic study of human diseases:  (1) for human diseases, one cannot arrange
matings at will but rather must retrospectively interpret existing families;
and (2) for human diseases the trait may not be simply related to the genotype
at a single gene (although this may be true also for many traits in
experimental organism).  Even with a dense genetic map of {DNA} polymorphisms,
human genetic mapping confronts several special problems of incomplete
information (Lander 1995):  for individuals homozygous at a gene, one cannot
distinguish between the two homologous chromosomes based on the genotype at
the locus; for individuals heterozygous at a gene, one cannot tell which allele
is on the paternal chromosome and which is on the maternal chromosome unless
one can study the individual's parents; and information for deceased
individuals (or for those who choose not to participate in a genetic study) is
completely missing. For these reasons often one cannot simply count
recombinants directly to estimate recombination frequencies.

The theory of {\bf population genetics} is increasingly used in human genetics
(e.g.  Schork et al.  1998; Weeks \& Lathrop 1995).  For each generation there
is an element of chance in the drawing of gametes that will unite with other to
form the next generation.  Chance alone can result in changes in allele
frequency, and as this change does not follow any predetermined direction, it
is known as random genetic drift (Hartl \& Clark 1997).  Mutation is a change
in DNA sequence and provides new variation.  Migration among populations or
shared selection decreases divergence among them.  Selection (e.g.,
differential survival or fertility of genes of certain allelic types) in favour
of a specific allele may increase frequency of the haplotype containing that
allele.  Assuming random mating and absence of disturbing forces such as
migration, mutation, and selection for the gene of interest, the genotype
distribution is governed by Hardy-Weinberg equilibrium (HWE).  Therefore for a
gene with two alleles A and a, each with frequency $p$ and $q$, the frequencies
of genotypes AA, Aa and aa would be $p^2$, $2pq$ and $q^2$.  Under random
mating the genotype distribution remains in these Hardy-Weinberg proportions
from one generation to the next.  {\bf Assortative mating} refers to any system
of mating in which mate choice is influenced by genotype or phenotype.  In
positive assortative mating, mates are more like each other than they would be
by chance, and such mating tends to increase homozygosity.

To make inferences from genetic data, a statistical model is often required.
Essentially, {\bf statistical inference} is concerned with parameter
estimation and hypothesis testing.  The optimality of a statistical test is can
be assessed by many criteria:  the {\bf validity} of a test indicates if it
produces the correct type I error under the null hypothesis;  the probability
of rejecting the null hypothesis when an alternative is true is {\bf power};
the resistance to departures from the idealised assumptions is called {\bf
robustness}.

\section{Mean and variance of noncentral $\chi^2$ distribution}

Since statistical inference is often via likelihood ratio tests which are
asymptotically $\chi^2$, noncentral $\chi^2$ distribution is often used in
statistical power analysis.  Here we give the characteristic function, cumulant
generating function and conditional expectations.  The characteristic function
for a random variable $\xi$ with probability measure $P$ is the complex valued
function (Fourier transform) of the variable $t\in R^1$ given by $\phi(t) =
E(\exp(itx))=\int_{-\infty}^\infty\exp(itx)dP(x)$ where $i=\sqrt{-1}$.  If
$\xi$ has an absolute moment of order $k$, then $\phi(t)$ is $k$ times
continuously differentiable and $\phi^{(k)}(0)=i^kE\xi^k, k=0,1,\dots$ (Note
that the definition and result apply to both discrete and continuous random
variables).  Now let $X_i$, $i=1,\ldots,\nu$ be independent variables with
distribution and $N(\mu_i,1)$ characteristic function
$\exp({\mu_i^2it}/{(1-2it)})/\sqrt{1-2it}$ (Grimmett \& Stirzaker 1992), then
random variable $Y = \sum_{i=1}^\nu X_i^2$ has characteristic function $\phi(t)
= \exp[{(it\delta)}/{(1-2it)}]/[(1-2it)^{\nu/2}]$, where
$\delta=\sum{i=1}^\nu\mu_i^2$.  The random variable $Y$ is said to have a
noncentral $\chi^2$ distribution with $\nu$ degrees of freedom and
noncentrality parameter (NCP) $\delta$ ($\chi^2_{(\nu,\delta)}$).  Further we
have $\phi^{(1)}(t) = \phi(t){(i\nu+2t\nu+i\delta)}/{(1-2it)^2}$,
$\phi^{(2)}(t) = \phi^{(1)}(t){[(4i+i\nu)(1-2it)+i\delta]}/{(1-2it)^2}$ + ${(2
\nu)}/{(i\nu+2t \nu+i\delta)}$ so $E(Y) = \nu+\delta$, $E(Y^2) = -\phi^{(2)}(0)
= (\nu+\delta)(4+\nu+\delta)-2\nu$ and $V(Y) = 2\nu+4\delta$.  Similar
expressions for moments of arbitrary order can be obtained from
$\log(E(\exp(tx)))$ called cumulant.  The $r$th cumulant is $k_r =
2^{r-1}(r-1)!(\nu+r\delta)$ (Patnaik 1949).  The mean and variance can also be
derived in a hierarchical model setting (Casella \& Berger 1990, p157),
$Y|K\sim \chi^2_{n+2k}, K\sim Poisson(\delta/2)$ then $E(Y) = E(E(Y|K)) =
E(\nu+2K) = \nu+\delta$, similarly $V(Y) = V(E(Y|K)) + E(V(Y|K)) =
V(\nu+2K)+E(2(\nu+2K)) = 4V(K)+2\nu+4E(K) = 2\nu+4\delta$.  We have used the
fact that $E(K)=V(K)=\delta/2$.  Power of a $\chi^2$ statistic given
significance level $\alpha$ can be obtained as
$\int^\infty_{\chi_{\alpha(\nu,0)} d\chi^2(\nu,\delta)}$, where
$\chi_{\alpha(\nu,0)}^2$ is the $100(1-\alpha)$ percentage point of the central
$\chi^2$ with $\nu$ degrees of freedom, and $\delta$ is the NCP.


\section{Segregation analysis}

The inference of mode of inheritance from pedigree data is called segregation
analysis.  Complex segregation analysis (Elandt-Johnson 1971; Lalouel \& Morton
1981) is the statistical method used in handling family data when two or more
distinct and functionally independent segregation parameters are involved in
the analysis.  Traditionally it deals with the following situations
(Elandt-Johnson 1971, p497) ``{\em (a) There are two phenotypic forms of a
certain genetic character; neither form is rare, and both are controlled by one
(or more) loci.  (b) There are more than two phenotypic forms controlled by a
certain genetic system (e.g.  multiallelic inheritance or multilocus
inheritance with or without epistasis and/of with or without linkage).  (c)
Some of the models discussed in (a) or (b) can be complicated by incomplete
penetrance or different fitnesses of genotypes}''.

The likelihood of phenotypic data $X$ of a pedigree with size $n$ can be
written as follows
\begin{eqnarray}
L(X) &=& \sum_{g_1}\sum_{g_2} \ldots \sum_{g_n}
\Pi_{j=1}^nP(X_j|g_j)\Pi_{k=1}^fP(g_k)\Pi_{m=1}^{n_f}\tau(g_m|g_{m1},g_{m2})
\label{flike}
\end{eqnarray}
where $g_i$ is the multilocus genotype of individual $i$, $f$ the number of
founders, $n_f$ the number of nonfounders, $P(.)$ the genotypic frequency,
$P(.|.)$ the penetrance, $\tau(.|.,.)$ the transmission function, $m_1$ and
$m_2$ the parental indices of individual $m$.  The tranmission function (Elston
\& Stewart 1971) specifies the probabilities of the three major locus genotypes
(AA, Aa, aa) transmitting the normal allele (A), to be (1,0.5,0) in the
Mendelian case, and test of heterozygote transmission probability being 0.5 may
detect departure from Mendelian model, while setting the transmission
probabilities to be the same tests the transmission of major determinants
(Morton et al.  1983).  An algorithm for calculation of expression
(\ref{flike}) in general pedigree was developed by Elston and Stewart (1971).
Expression (\ref{flike}) can be extended to incorporate environmental factors
or covariates.  Given family data, likelihoods can be obtained under models
ranging from Mendelian, non-Mendelian to the general models, from which the
best-fitting model is selected (Elandt-Johnson 1970; Rao \& Elandt-Johnson
1971; Morton \& MacLean 1974; Boyle \& Elston 1979; Elston 1980; Morton et al.
1983).

Under a generalised single locus model in which the disease locus is biallelic
with disease allele a (with frequency $q$) and normal allele A (with frequency
$1-q$), there are three possible genotypes AA, Aa and aa.  The mode of
inheritance can be delineated by the frequency of a and penetrances for AA, Aa
and aa.  Therefore Mendelian dominant trait has mode of inheritance ($q$, 0, 1,
1) and Mendelian recessive trait as ($q$, 0, 0, 1), while non-Mendelian trait
has penetrances taking any values between 0 and 1.  Under a mixed model, a
phenotype of interest ($x$) is more appropriately assumed to be a result of
major locus, polygenic, common and random environmental effects (Morton \&
MacLean 1974).  Suppose the major locus is biallelic with alleles A and a,
genotypic effects of AA, Aa and aa can be characterised by $z$, $q$, $t$, $d$,
where $z$ is the mean effect of AA, $q$ is the allele frequency of a, $t$ is
the displacement between AA and aa and $d$ is the dominance.  The genetic
effects of genotypes AA, Aa and aa are $z$, $z+dt$ and $z+t$ with frequencies
$p^2$, $2pq$, and $q^2$ under HWE.  When the major locus effect has mean 0 and
variance 1, we have $z=-(tq^2+2pqdt)$ and
$t^2=1/[(pq)^2(q+2pd)^2+2pq(d-q^2-2pqd)^2+q^2(1-q^2-2pqd)^2]$, so that the only
$q$ and $d$ are free parameters.  Computer program {\bf POINTER} (Morton \&
MacLean, 1974; Lalouel \& Morton, 1981; Morton et al.  1983) incorporates male
and female mutations and X-linked case, and obtains maximum-likelihood
estimates (MLEs) by iterating upon the following:  $\mu$, mean of $x$; $V$,
variance of $x$; $d$, $t$, $q$, as above; $H$, polygenic heritability; and $B$,
relative variance due to common environment.  Phenotype specification may
concern a quantitative measurement, a dichotomous affection status, or both
(Morton et al.  1983).  Phenotypic liability to affection ${y}$, is related to
${x}$ by ${y}={x}+{w}$, where ${w}\sim N(0,W)$ and $cov({x},{w})=0$.
Individuals are affected whenever liability $x$ is greater than some threshold.
For such a specification to be independent of any particular model of
inheritance in segregation analysis, one must provide an estimate of the prior
probability of affection in the reference population.  {\bf POINTER} was
extended by {\bf PAP} (Hasstedt \& Cartwright 1981; Hasstedt 1982, 1994) which
parameterises total mean ($\mu$), the total standard deviation ($\sigma$), the
frequency ($q$), dominance ($d$) and displacement ($t$) at major locus and
polygenic heritability ($h^2$), and parent-to-offspring transmission
probabilities ($\tau_1, \tau_2, \tau_3$) for the three genotypes at one locus.
Major loci could be inferred sequentially, i.e., after one major locus is
inferred it is fixed with its estimated parameters and the second major locus
is tested, and so on (Hasstedt et al, 1997).  The relationship between {\bf
POINTER} and {\bf PAP} can be summarised in Table~\ref{segreg} (Khoury et al.
1993; Ziegler \& Hebebrand 1998).

\begin{table}[h]\centering
\caption{Relationship between parameters in the Mendelian ``mixed models''}
\label{segreg}
\begin{tabular}{lll}
\hline
{\bf PAP} & {\bf POINTER} & Conversion\\
\hline
p frequency of $A_1$ allele & q frequency of low allele & note if $\mu_1$ is "low" \\
$\mu_1$ mean of genotype $A_1A_1$ & $\mu$ population mean &$\mu=p^2\mu_1+2pq\mu_2+q^2\mu_3$\\
$\mu_2$ mean of genotype $A_1A_2$ &$V$ population variance &$V=\sigma_W^2+\sigma_{ML}^2$\ddag\\
$\mu_3$ mean of genotype $A_2A_2$ & $t$ displacement between & $t=\mu_3-\mu_1$\\
& homozygotes & \\
$\sigma_W^2$ within genotype & $d$ deviation due to&$d={\mu_2-{\left( {\mu_3-\mu_1}\over{2}\right)}}$\\
variance& dominance& \\
$H_p$ proportion of $\sigma_W^2$ &$h^2$ narrow sense &$h^2={H_p\left(\sigma_W^2\over{\sigma_W^2+\sigma_{ML}^2}\right)}$\\
attributed to additive&heritability=$\sigma_A^2 \over V$&\\
polygenes=$(\sigma_A^2/\sigma_W^2)$& &\\
\hline
\end{tabular}
\ddag Variance due to major locus,
$\sigma_{ML}^2={p^2(\mu_1-\mu)^2+2pq(\mu_2-\mu)^2+q^2(\mu_3-\mu)^2}$
\end{table}

Assuming Mendelian inheritance, genetic effects on a trait was traditionally
examined for multi-modalities of its distribution (e.g.  MacLean et al.  1976).
Genetic covariate effects on continuous and discrete traits can be examined via
regressive models (Bonney 1984, 1986) and implemented in {\bf SAGE}
(http://darwin.cwru.edu) modules REGD, REGC and REGTL.  Methods using
generalised estimating equation (GEE) were also proposed (e.g.  Lee et al.
1993; Zhao 1994; Lee \& Stram 1996; Tr\'{e}gou\"{e}t \& Tiret 2000).

Owing to ascertainment in affected individuals, segregation analysis may suffer
from bias if an ascertainment correction is not made (Ewens 1991).  The power
of segregation analysis was investigated by Konigsberg et al.  (1989), Borecki
et al.  (1994, 1995).  Genetic marker can in principle be incorporated into a
formal combined segregation and linkage analysis (e.g.  Borecki et al.  1994).
Such models have also been extended to consider polygenic and multifactorial
effects.


\section{Linkage analysis}

The study of cosegregation of genetic markers with putative disease genes in
families is called {\bf linkage analysis}.  Alternatively, it ``{\em refers to
the ordering of genetic loci on a chromosome and to estimating genetic
distances among them}'' (Ott 1999).  It requires specification of the
relationship between map distance and recombination.  The simplest case assumes
there is no interference so crossovers occur as a Poisson process.  In this
case, map function $M(x)$ is obtained from the probability that a Poisson
random variable with mean $x$ is odd, that is, $\sum_{k=odd}\exp(-x){x^k}/{k!}
= \exp(-x)/2 \sum_{k}\left({x^k}/{k!}-{(-x)^k}/{k!}\right) = (1-\exp(-2x))/2$.
It can also be derived from $M(x+\delta x)=M(x)(1-\delta x)+(1-M(x))\delta x$,
${dM(x)}/{dx}=(1-2M(x))$, $\ln(1-2M(x))=-2x$, $M(x)=(1-\exp(-2x))/2$ since
$M(0)=0$.  Recent discussions of models for recombination include Zhao et al.
(1995a, 1995b), Lange (1997), Speed (1997), Ott (1999), Broman \& Weber (2000),
and Thompson (2000c).

Equation (\ref{flike}) underlies the Elston-Stewart method for linkage analysis
(Elston \& Stewart 1971; Cannings et al.  1978).  Methods based on hidden
Markov model (Baum et al.  1970, 1972), was developed by Lander \& Green
(1987).  The Elston-Stewart algorithm is linear on number of individuals while
the Lander-Green algorithm is linear on the number of markers.  The
Lander-Green algorithm is based on the notion of inheritance vectors, indicator
arrays with element taking values 0 or 1 to indicate whether paternal or
maternal allele is transmitted.  Consider a pedigree with $N$ meiosis and three
loci A, B and C with inheritance vectors $\alpha$, $\beta$ and $\gamma$, the
probability of observing phenotype data can be expressed in terms of these
inheritance vectors.  For loci A and B, the probability of observing phenotype
data $a$ and $b$ can be expressed as follows (Idury \& Elston 1997)
\begin{eqnarray}
p(a,b)&=&\sum_{\alpha,\beta}p(a,b|\alpha,\beta)p(\alpha,\beta) \cr
      &=&\sum_{\alpha,\beta}p(\alpha,\beta)p(a|\alpha)p(b|\beta) \cr
&=&\sum_{\alpha}p(\alpha)p(a|\alpha)\sum_{\beta}p(\beta|\alpha)p(b|\beta) \cr
      &=&2^{-N}P_aT_1P_b \label{lg1}
\end{eqnarray}
where $T_1$ is $2^N\times 2^N$ transmission matrix with elements
$t_{\alpha,\beta}=\theta_1^p(1-\theta_1)^{N-p}$, $\theta_1$ is the reombination
rate, $p$ being determined by $\alpha$ and $\beta$.  When the third locus C is
included we have.
\begin{eqnarray}
p(a,b,c)&=&\sum_{\alpha,\beta,\gamma}
p(a,b,c|\alpha,\beta,\gamma)p(\alpha,\beta,\gamma) \cr
&=&\sum_{\alpha,\beta,\gamma}p(\alpha,\beta,\gamma)
p(a|\alpha)p(b|\beta)p(c|\gamma) p(\gamma|\beta,\alpha)p(\beta|\alpha)p(\alpha) \cr
&=&\sum_{\alpha}p(\alpha)p(a|\alpha)\sum_{\beta}p(\beta|\alpha)p(b|\beta)
\sum_{\gamma}p(\gamma|\beta)p(c|\gamma) \cr &=&2^{-N}P_aT_1P_bT_2P_c
\label{lg2} \end{eqnarray}
where $T_2$ is defined similarly to $T_1$.  This yields an algorithm faster
than the original Lander-Green algorithm.  Kruglyak \& Lander (1998) made
further improvement to (\ref{lg1}) and (\ref{lg2}) by fast Fourier transform
(FFT).  Strauch et al.  (2000) extended it to incorporate imprinting and
two-locus model.  With the limitations of both Elston-Stewart and Lander-Green
algorithms, Markov chain Monte Carlo (MCMC) methods and associates become
important alternatives (Lange \& Sobel 1991; Thomas \& Cortessis 1992; Thompson
et al.  1993; Kong et al.  1993; Thompson 1995; Lin 1996; Heath 1997; Thompson
2000a, 2000c; Lee \& Thomas 2000).

The test of linkage is via the ratio of likelihoods assuming linkage and no
linkage.  The base-10 logarithm of the ratio is termed the lod score (Morton
1955), so that $2\ln 10$ lod is approximately $\chi^2$ distributed with one
degree of freedom.  The {\bf location score} is the natural log of likelihood
raio assuming linkage and no linkage, closer to $\chi^2$ without the need to
multiply $\ln 10$.  The alternative hypothesis of linkage is restricted to
$0<\theta<0.5$, therefore the test turns out to be one-tailed, the pointwise
significance can be determined by 0.5 ($\chi^2>2\ln10$ lod), since $2\ln 10$
lod is a 50:50 mixture of a point mass at 0 and $\chi_1^2$ (Self \& Liang 1987;
Nyholt 2000).  A lod score of 3, or a likelihood ratio of 1,000, is commonly
used to indicate significant linkage, which can be translated into the odds of
$\sim$20:1 in favour of linkage, or a significance level of 0.05 (Ott 1991).
In the context of genome scanning using pedigree data, the genomewide
significance of 0.05 is achieved at a pointwise significance of $4.9\times
10^{-5}$, or lod score of $\sim$ 3.3 (Lander \& Kruglyak 1995; Ott 1999; Nyholt
2000).  A lod score of less than $-2.0$ is customarily accepted as conclusive
evidence for the exclusion of linkage.  Genetic heterogeneity can be allowed
for using the admixture model for heterogeneity (Smith, 1963).  Under this
model, the probability of the trait being linked in a given pedigree is
$\alpha$; with probability $1 - \alpha$ the trait is unlinked.  This model
assumes that while different pedigrees may have different genetic forms of the
disease, within a pedigree only a single genetic form is present.  If genetic
heterogeneity is allowed for, two different lod scores are calculated:  the
standard lod score which assumes genetic homogeneity, and a lod score which
allows for maximisation of the likelihood function over both the recombination
fraction and the linked fraction $\alpha$.  For rare recessive disorders,
affected individuals in inbred families tend to have more homozygosity by
descent at the disease locus, this leads to the method of homozygosity mapping
(Smith 1953; Lander \& Bostein 1987).

Power for a traditional linkage study is the probability of obtaining a maximum
lod score $\geq 3$ for a linked marker (Morton 1955).  If the number of
recombinants and nonrecombinants can be obtained directly (in the so-called
direct method of linkage, say offsprings in a family of a phase-known double
backcross mating can be scored recombinants and nonrecombinants, Ott 1985),
this could be particularly simple.  For a given true recombination fraction,
$\theta$, significance level $\alpha$, and a power $1-\beta$ (e.g.
$\alpha=0.0001$, $z_{1-\alpha}=3.7$; $\beta=0.2, 0.1$, $z_{1-\beta}=0.84,
1.28$), the required sample size is approximately
$N=\left[{(z_{1-\alpha}/2+z_{1-\beta}\sqrt{\theta(1-\theta))}}/{(\theta-1/2)}
\right]^2$ (Elandt-Johnson 1971, expression [13.69]).  For $z_\alpha=3$,
$\beta=0.80$, $\theta=0.05$, one finds $N=20$, with $N$ being the total number
of recombinants and nonrecombinants (Ott 1991, Table 5.8).  A rough guide is as
follows (Ott 1991, pp257-8):  a good picture of the properties of the disease
including its phenotype, mode of inheritance, population frequency is obtained
first.  For a quantitative phenotype, an analysis of mixture of distributions
may be required.  The number of families (e.g.  N=20) required to find linkage
to a hypothetical marker in phase-known meioses needs one offspring to each
sibship to be added for phase-unknown.  To adjust for incomplete marker
informativeness, the number of families required is multiplied by the inverse
of the marker's heterozygosity.  With incomplete penetrance, $N$ must be
multiplied by the inverse of the relative expected lod score (ELOD).
Heterogeneity may be allowed for by further multiplying the number of offspring
by the inverse of the relative efficiency (ratio of variances).  When 20\% of
families are of the unlinked type ($\alpha=0.80$), with $\theta=0.05$, the
number of offspring must be multiplied by the inverse of the ratio of the
variances, that is, by $(0.075/0.042)^2=3.2$ (0.075 and 0.042 being the
standard errors of $\theta$ for $\alpha$=1 and 0.8 when there are 10 families
with 3 phase-known meioses each.  Ott 1991, Table 9.7).  Errors in marker
typing may be allowed for under a simple misclassification model.  For example,
with $\theta=0.05$ and a misclassification rate of 0.05, the number of
offspring has to be increased by a factor of 1/0.77=1.3 (0.77 being the
relative ELOD of the recombination fraction estimate in the presence of
missclassification.  Ott 1991, Table 10.3).  Therefore $N=20$ meioses are
increased to $20 \times 3 \times 3.2 \times 1.3 \approx 250$ meioses by a
penetrance of 50\%, a proportion of linked families of 80\%, and a
misclassification rate of 5\%.  Power calculation of a proposed linkage study
can be formally done using {\bf SIMLINK} (Ploughman \& Boehnke 1989), {\bf
SLINK} (Ott 1989; Weeks et al.  1990) and more recently {\bf Allegro}
(Gudbjartsson et al.  2000), more details and practical examples will be given
in Chapter 5.

Lod score analysis is most powerful when parameters of the genetic model are
known.  Misspecification of these parameters not only decreases power to detect
linkage but also introduces bias in recombination estimate, especially when
wrongly specified the dominance (Clerget-Darpoux et al.  1986).  A
traditionally model-free approach is the allele-sharing method, in which excess
in allele sharing between affected members in a pedigree is used to test for
linkage between a marker locus and a disease locus, in the hope that
aggregation in such families tend to be more genetic and less heterogeneous.
The simplest allele-sharing method is affected sib-pair method originated from
Penrose (1935).  Genes shared by relatives from common ancestor are called {\bf
IBD}, or identity by descent.  The IBD probabilities for sib pairs were derived
by Suarez et al.  (1978) and a more comprehensive derivation was given by Guo
(2000).  Allele-sharing is most successfully applied when the marker locus is
extremely polymorphic.  The so-called affected pedigree member (APM) method
(Lange \& Weeks 1988) examines allele-sharing in extended pedigree based on
identity-by-state (IBS) relationships, $Z_{ij} =
{1/4}\sum^2_{a=1}\sum^a_{b=1}\delta(A_a,B_b)f(A_a)$ where $\delta(.,.)$ is the
Kronecker delta function with $\delta(s,s')$ taking values 1 or 0 according to
whether or not $s$ and $s'$ shares alleles IBS; $f(A_a)$ is a weight function
taking forms of $1$,$1/\sqrt{p_{A_a}}$, $1/\sqrt{p_{A_a}}$, the latter two give
more weight to rare-allele sharing.  Several limitations of APM method have
been raised (Shih \& Whittemore 2001).  First, it is sensitive to
misspecification of marker allele frequencies.  Second, the null distribution
of the test statistic may be skewed, leading to a potential anticonservative
test.  Third, it ignores IBD information available and is thus less powerful
than methods based on IBD sharing.  A nonparametric linkage statistic (NPL) is
based on IBD configurations between pairs of relatives (NPLpair) or all
relatives (NPLall) (Whittemore \& Halpern 1994a, 1994b; Kruglyak et al.  1996).
Davis et al.  (1997) proposed to use IBD information and implemented their
method in computer program {\bf SimIBD}.  A summary of power of allele-sharing
method was given by Shih \& Whittemore (2001).

Variance component analysis is the study of continuous traits and their
variation due to genetic and environmental factors (Hopper \& Mathews 1982;
Goldgar 1990; Goldgar \& Oniki 1992; Schork 1993; Fulker et al.  1995; Beaty
1997; Lange 1997; Almasy \& Blangero 1998; Williams et al.  1999; Pratt et al.
2000).  Under this model, the variance of a quantitative trait is partitioned
into various genetic and environmental components, which may include additive,
dominance, shared and nonshared environment.  The genetic component may be
further partitioned into a QTL (quantitative trait locus) component and
residual genetic compoent, when genetic marker data is available.  Denote the
$k$th allele at the QTL locus to be $a_k$, individuals with genotype $a_k/a_l$
has average trait value $\mu_{kl}=\mu_{lk}$, Statistical inference is based on
the covariance structure of the quantitative traits between individuals, which
is expressed in terms of several components and their correlations.  The
correlation of additive genetic component is determined by {\bf kinship
coefficient} ($\phi_{ij}$, the probability of randomly drawing an allele in
individual $j$ being IBD to an allele at the same locus randomly drawn from
individual $i$).  The correlation of dominance is $\Delta_{7ij}$ (Jacquard
1974, the probability that both alleles at the locus being IBD).  The
correlation of environmental factor is $\gamma_{ij}$ (the probability of
sharing a particular environmental factor).  Values for $\phi_{ij}$ and
$\Delta_{ij}$ for common pairs of relatives are known, e.g., 1/4 and 1/8, for
sibs, and $1/2^{(k+1)}$ and 0 for most other outbred relationships, where $k$
is the degree of relationship.  The covariance between relatives $i$ and $j$
with traits $X_i$ and $X_j$ can be expressed as
$Cov(X_i,X_j)=2\phi_{ij}\sigma_a^2
+\Delta_{7ij}\sigma_d^2+\gamma_{ij}\sigma_c^2+\delta_{ij} \sigma_e^2$, where
$\sigma_a^2$ and $\sigma_d^2$ are the additive and dominance effects of the
determining locus, and $\delta_{ij}$ is the Kronecker symbol, i.e.  1 if $i=j$
and 0 otherwise.  The $N\times N$ expected variance-covariance matrix for an
entire family of $N$ individuals with data $X=(X_1,...,X_N)$ can be written as
$ \Omega=2\Phi\sigma_a^2+\Delta\sigma_d^2+\Gamma\sigma_c^2+I \sigma_e^2$, where
$\Phi=\{\phi_{ij}\}$, $\Delta=\{\delta_{ij}\}$, $\Gamma=\{\gamma_{ij}\}$ are
written in matrix forms.  Assuming $X$ follows multivariate normality, the
likelihood function for the pedigree is
$(2\pi)^{-\frac{N}{2}}|\Omega|^{-1/2}\exp[(X-E(X))'\Omega^{-1}(X-E(X))]$,
where $E(X)$ may be a constant or a linear function of covariates.  The total
likelihood is the product of all the likelihoods of individual families.
Likelihood ratio test can be applied to nested hypotheses about these
parameters.  Genetic markers can also be incorporated into the model to infer
the quantitative trait locus (QTL), say $q$.  Regardless of the dominance and
environmental effects, the variance-covariance matrix $\Omega$ is given by
$\Omega=\hat\Pi\sigma_q^2+2\Phi\sigma_a^2+I\sigma_e^2$, where $\hat\Pi$ is a
matrix whose elements $\hat\pi_{ij}$ are the estimated proportion of genes
shared IBD at the QTL by individuals $i$ and $j$, $\sigma_q^2$ being the
genetic variance due to QTL, $\Phi$ being the kinship matrix for the pedigree,
$\sigma_a$ being the residual additive genetic variance, $I$ being identiy
matrix, and $\sigma_e^2$ being the variance due to individual-specific random
environmental effects.  For the model with $n$ QTLs the first term of the right
hind side is the sum of similar terms from the $n$ QTLs (Almasy \& Blangero
1998).  Method of QTL linkage analysis in sib pairs was discussed by by Haseman
\& Elston (1972), Wright (1997), Elston et al.  (2000), Sham \& Purcell (2001).
A GEE approach was proposed by Amos (1994, 1996).

Power of variance component analysis was investigated by Fulker \& Cherny
(1996), Wijsman \& Amos (1997), Williams \& Blangero (1999), Page et al.
(1999), Amos et al.  (2001).  Exact expression for sib pairs was given by
Williams \& Blangero (1999), in which a test of $\sigma_q^2=0$ has
noncentrality parameter $\hat\delta=q^2(h^4+4)/2/(h^4-4)^2$, where
$q^2=\sigma_q^2/\sigma^2$, $h^2=(\sigma_q^2+\sigma_a^2)/\sigma^2$, $\sigma^2$
being the total phenotypic variance.  For a test of linkage having 80\% power
and a size of 0.001 (a lod score of 3), the critical value of the $\chi^2$ test
statistic is 20.78, so that the number of sib pairs required is
$N=20.78/\hat\delta$, i.e., $2N$ individuals.  One of the major concerns of
both the variance components model and the Haseman-Elston regression methods is
the robustness.  For example, the result of linkage analysis could depend on
families with extreme scores (Amos \& de Andrade 2001, Dr Tao Li personal
communication).

Computer implementation of linkage analysis has drawn considerable attetion.
Following the work of Haldane \& Smith (1947), Smith (1953) and Morton (1955),
Elston and Stewart (1971) formulated an algorithm for general pedigrees without
loops.  This was subsequently generalised by Ott (1974) and implemented in {\bf
LIPED}, Lange \& Boehnke (1975), Lange et al.  (1988) in {\bf MENDEL/FISHER},
Lathrop et al.  (1984) in {\bf LINKAGE}, and (Cottingham et al.  1993) in {\bf
FASTLINK}.  Both {\bf LINKAGE} and {\bf FASTLINK} have modules {\bf ILINK},
{\bf MLINK} and {\bf LINKMAP}.  Lander-Green algorithm was implemented in {\bf
MAPMAKER} and associates {\bf GENEHUNTER} (Kruglyak et al.  1996), {\bf
GENEHUNTER PLUS} (Kong \& Cox 1997), {\bf Allegro} (Gudbjartsson et al.  2000),
{\bf GENEHUNGER/IMPRINTING} and {\bf GENEHUNTER/TWOLOCUS} (Strauch et al.
2000).  Likelihood based methods for affected sib pairs incorporating the
possible triangle constraint are implemented in {\bf SPLINK} (Holmans 1993).
{\bf ESPA} (Sandkuijl 1989) uses {\bf MLINK} to infer incomplete information
and does $\chi^2$ test for increased allele sharing among affected sib pairs.
{\bf APM} implements affected pedigree member method (Weeks \& Lange 1988).
Variance component linkage analysis has been implemented in {\bf MIM} (Goldgar
1990), {\bf SOLAR} (Almasy \& Blangero 1998), {\bf ACT} (Amos 1994).  Lange
(1997) described method for two quantitative traits.  Haseman-Elston method has
been implemented in {\bf SAGE}, which also includes Bonney's regressive model
and IBD calculation of a general pedigree using an extended Lander-Green
algorithm.

Owing to the limited number of meioses the resolution of linkage from family
data is usually no finer than 1cM (Boehnke 1994).  Therefore there is a need
(1) to redefine disease and increase the relative risk among relatives.  (2) to
fine-structure LD mapping using allelic or haplotype association (Kruglyak \&
Lander 1995; Nevanlinna et al.  1980; de la Chapelle 1993, 1998).


\section{Association analysis}

Association analysis is the search for genetic markers that occur at a
different frequency between cases and controls.  An allele is said to be
positively associated with the disease if it is more frequent in affected
probands than in unaffected controls.  This could occur for many reasons
(Lander \& Schork 1994), for example, (1) the allele itself is a cause of the
diseases; (2) the allele is in linkage disequilibrium (LD) with a disease
causing gene; and (3) the association is an artifact due to population
admixture.  The simplest test of allele frequency differences between cases and
controls is $\chi^2$ test (Sham \& Curtis 1995b).  If more than one locus is
involved this could be extended to haplotype analysis (Xie \& Ott 1993;
Terwilliger \& Ott 1994; Zhao, Curtis \& sham 2000).  Considerable attention
has been focused on case-control design (Morton \& Collins 1998; Pritchard \&
Rosenberg 1999; Pritchard et al.  2000; Long \& Langley 1999; Devlin \& Roeder
1999; Risch 2000).  Successful examples of case-control studies include the
human leukocyte antigen (HLA) associations and a number of diseases including
insulin-dependent diabetes melitus (IDDM), multiple sclerosis, rheumatoid
arthritis, psoriasis and celiac disease.  Risch (2000) pointed out the
possibility that the high false positive rate from case-control designs may be
due to a low prior probability of gene polymorphisms causally related to the
disease outcomes.

Population admixture or substructure has been the major concern of association
study, as allele or haplotype frequency differences between populations may
lead to spurious association (e.g.  Mckeigue 1997; Pritchard et al.  2000a,
2000b; Pritchard \& Przeworski 2001).  For nuclear families with a single
affected child, Rubinstein et al.  (1981), Falk \& Rubinstein (1987) proposed
forming controls with parental marker alleles that have not been transmitted to
the child.  Thomson (1988) proposed a similar method called ``affected family
based controls (AFBAC)'' (implemented in computer program AFBAC).  Further
investigations were made by Ott (1989), Terwilliger \& Ott (1992), Spielman et
al.  (1993), Knapp et al.  (1993).  The popular transmission/disequilibrium
test (TDT) was coded by Spielman et al.  (1993).  The TDT method can be applied
to large pedigrees with many affected subjects or to a simplex family with an
affected subject and his/her parents.  However a simplex family is informative
for linkage only when linkage disequilibrium exists, i.e., when the likelihoods
of the coupling and repulsion linkage phases are unequal.  Therefore TDT can be
considered as a test for linkage in the presence of linkage disequilibrium.
Methods of Schaid \& Sommer (1993, 1994) allow one to estimate separately the
magnitude of the relative risks of disease for individuals being homozygous and
those being heterozygous at the candidate-gene locus.  The first is a HWE
likelihood method, and the second is a conditional (on parental genotype, CPG)
likelihood method, appropriate when HWE is absent.  Knapp et al.  (1995) showed
HWE method to be asymptotically at least as efficient as the CPG method,
irrespective of the mode of inheritance.  They also obtained the analytical
MLEs for the parameters of HWE method and showed the MLEs of CPG method to be
the solution of a simple cubic equation.  The original TDT has been extended to
multiallelic marker by Bickeb\"{o}ller (1995), Sham \& Curtis (1995a), Spielman
\& Ewens (1996), Morris et al.  (1997a, b), Wilson (1997), Martin et al.
(1997), Lazzeroni \& Lange (1998).  Schaid (1996) and Sham (1997) both proposed
score statistics from logistic regression.  Koeleman et al.  (2000) proposed
variation based on Sham \& Curtis (1995a).  When information from one parent is
unavailable the use of parent-offspring pair may induce bias (Curtis \& Sham
1995b; Sun et al.  1999).  In the absense of parental information, inference
can be based on extra siblings (Curtis 1997; Spielman \& Ewens 1998; Boehnke \&
Langefeld 1998; Horvath \& Laird 1998; Schaid \& Rowland 1998; Whittaker \&
Lewis 1999; Siegmund et al.  2000), which is a ``horizontal'' approach in
contrast to ``vertical'' approach by reconstruction from missing parents
(Clayton 1999) or both (Knapp 1999b).  Reconstruction of parental information
has been extensively discussed (Chiano \& Clayton 1998; Weinberg et al.  1998;
Weinberg 1999a,b; Umbach et al.  2000).  Other developments include the Monte
Carlo simulation (Cleves et al.  1997; Zhao, Sham \& Curtis 1999; Whittaker \&
Thompson 2000), the handling of arbitrary family structures or missing data
patterns (Martin et al.  2000; Monks \& Kaplan 2000), Whittemore \& Tu 2000;
Rabinowitz \& Laird 2000), haplotype methods (Clayton \& Jones 1999; Clayton
1999; Xiong \& Jin 2000; Zhao et al.  2000; Dudbridge et al.  2000), and
quantitative traits (Allison 1997; Rabinowitz 1997; Fulker et al.  1999; George
et al.  1999; Allison et al.  1999; Van den Oord 2000; Waldman 1999; Abecasis,
Cardon \& Cookson 2000; Rabinowitz \& Laird 2000; Laird et al.  2000; Lake et
al.  2000; Monks \& Kaplan 2000; Zhu \& Elston 2001; Zhu et al.  2001).
Lunetta et al.  (2000) considered general association models for an arbitrary
phenotype and score statistics.

An elaboration of Clayton (1999) as in the the computer program {\bf TRANSMIT}
is given here.  It is ``{\em for estimating genetic associations from
probabilities of haplotype transmission to affected offspring when there may be
uncertain marker haplotype assignment}''.  Based on CPG likelihood, the
(log)haplotype relative risk parameters with respect to multiplicative model
for genotype risk, a score test $U^{T}V^{-1}U$ is constructed.  For known
parental haplotypes, $U$ is the difference between the vector of observed
marker haplotype frequencies in affected offspring and the frequencies expected
under Mendelian transmission, and $V$ is the variance of $U$ (assuming
Mendelian transmission).  When transmission is fully observed, this test
reduces to the usual Pearson $\chi^2$ test.  When parental haplotype is
uncertain, the observed transmission frequency is averaged over all the
possible assignments consistent with the observed data, weighting by their
posterior probabilities.  The population haplotype frequencies are estimated
from the data by EM, while the score test is justified using profile likelihood
argument.  The information matrix involving all parameters is
$I=\pmatrix{A&B\cr B^{T}&C}$, then $V=A-BC^{-1}B^{T}$ where $A$ and $C$
correspond to haplotype relative risks and haplotype frequencies, respectively.
A robust ``information sandwich'' estimator for the score avoids the need to
assume independence of the information from two affected siblings, an
assumption viable with large sample size and asymptotic behaviour is unreliable
with rare haplotypes, which may be user-controlled.  The estimator is derived
by assuming the variance of $U$ at the correct model to be $J=\pmatrix{D & E
\cr E^{T} & F}$, the variance for $U$ is then obtained from estimating
equations as $V=D+BC^{-1}FC^{-1}B^{T}-BC^{-1}E^{T}-EC^{-1}B^{T}$.  For the
correct model, $J=I$.  How common a haplotype must be in order to use the
$\chi^2$ tests is argued as follows.  Since difference between observed and
expected transmission $O-E$ $\sim (n/2,n/4)$, in order for $n/2>5$, then $n=10$
or $n/4=2.5$ is needed.  For rare haplotypes it offers aggregation but no
simulation options.  ``{\em The program works by imputation of the missing
information concerning parental genotypes and haplotype phase.  Inevitably,
this brings in a population model and it has been necessary to assume HWE model
and no population-admixture...}''

The power to detect association using a marker depends on many factors such as
the strength of the linkage disequilibrium between the marker and disease, the
age and frequency of the disease mutation, the recombination fraction between
the disease and marker, the increase in risk attributatble to the particular
disease-susceptibility locus under consideration, and the penetrances of the
different disease-locus genotypes.  (Terwilliger \& Ott 1992; Schaid \&
Sommer 1993; Weeks \& Lathrop 1995; Ott \& Rabinowitz 1997; Chapman \&
Wijsman 1998; Sham, Zhao \& Curtis  2000).

Many computer programs have been developed for association analysis.  {\bf
ASPEX} (Hinds \& Risch 1996) contains several programs to perform sib-pair
analysis and TDT in nuclear families.  For TDT it provides adjustment for
multiple testing, while {\bf GENEHUNTER} also provides TDT tests for up to 5
loci.  {\bf ETDT} implements Bradley-Terry logistic model for multiallelic
marker, and a module {\bf MCETDT} (Zhao, Sham \& Curtis 1999) for Monte Carlo
simulation.  Another associate {\bf LAMBDAA} is written for TDTmax test (Morris
et al.  1997).  {\bf SIBASSOC} is a derivation of {\bf ETDT} (Curtis 1997).
{\bf SDT} implements Spielman-Ewens (1997).  {\bf GASSOC} implements
multiallelic TDT of Schaid (1996).  {\bf XDT} and {\bf FBAT} implements methods
by Horvath \& Laird (1998), Rabinowitz \& Laird (2000), Lake et al.  (2000),
and Laird et al.  (2000).  {\bf PDT} implements pedigree disequilibrium test of
Martin et al.  (2000).  {\bf QTDT} implements several quantitative TDTs
(Abecasis et al.  2000).  A SAS program is available for obtaining
Spielman-Ewens, Bickeb\"{o}ller, Stuart statistics (Sham 1997) and for
evaluating power of {\bf ETDT}.  Combination of TDT and the measured haplotype
method has recently been proposed by Seltman et al.  (2001).  {\bf TRANSMIT}
(Clayton 1999) and {\bf MULTDT} (Zhao et al.  2000) were developed for
transmission/disequilibrium tests involving multiple marker loci.

The high resolution of association analysis relies on abundance of genetic
markers, especially with the availability of SNP (Wang et al.  1998;
Lindblad-Toh et al.  2000), which has advantages and disadvantages over
traditional markers (Kwok \& Gu 1999):  First, the mean density of SNPs is
approximately one per kilobase in the human genome, so that a SNP library will
be sufficient for various study designs.  Second, the mutation rate per
generation of SNPs is low, which makes it the best choice for association
studies.  Third, it is likely that a subset of SNPs are functionally important
in etiology of complex traits, given that many Mendelian disorders result from
single nucleotide change.  Fourth, low-cost, high-throughput, automatic
genotyping methods are available for efficient genotyping, making it possible
to conduct large population studies.  In contrast, microsatellite markers are
rare, with higher mutation rate and less amenable to high-throughput
genotyping.  However, methods that could handle massive data sets are not yet
well-developed.  Without a priori knowledge of genotyping errors the conclusion
may be biased.  SNP haplotypes will have to be constructed to match the
information content of microsatellites in association studies.  As illustrated
by Nickerson et al.  (1998) and Clark et al.  (1998) in their study of
lipoprotein lipase (LPL) gene, 9.7kb of genomic DNA within this gene reveals 88
variable sites among 71 healthy individuals.  Most of the variability occurs in
noncoding regions, with a high rate of interlocus recombination and a complex
pattern of linkage disequilibrium.  It was not possible to assume any SNP would
`{\em give reliable information about flanking sites}' and that a random
sampling of three of four SNPs in the 10kb analysed `would not be a reliable
method of detection of nearby causal variation'.  If these effects are typical,
they will result in considerable loss of power to detect any predisposing
disease alleles.  The characterisation of sequence variation across genomic
regions in general is far from over (Subrahmanyan et al.  2001).


\section{Coalescent models}

The completion of DNA sequencing should help to understand the biological
mechansims underlying human traits and offer opportunities to decipher enigmas
of evolution.  Coalescent theory (Felsenstein 1981; Kingman 1982, 2000; Hudson
1990; Lange 1997; Hartl \& Clark 1997) in particular is recognised as a
cornerstone for various statistical analyses of molecular population data (Fu
\& Li 1999):  First, it is a sample-based theory, proposing that description of
a sample is more relevant than that of a whole population.  Second, it is
efficient and motivates many algorithms for simulating population samples under
various population genetics models.  Third, it is particularly suitable for
molecular data, such as DNA sequence samples.

Consider a sample of $n$ sequences of DNA region from a population, and assume
there is no recombination between sequences.  These sequences are connected by
a single phylogenetic tree or genealogy, the root of the tree is the most
recent common ancestor (MRCA).  Under the assumption of neutrality and when $n$
is small relative to the total population size $N$, Kingman (1982) showed that,
to a first approximation, only two lineages coalesce at each event and that the
distribution of times between successive coalescent events has a geometric
distribution $P(t|i)=[1-i(i-1)/4N]^{t-1}[i(i-1)/4N]
\approx\exp[-i(i-1)t/4N][i(i-1)/4N]$, where $i$ is the number of lineages
remaining and $t$ is the number of generations until the next coalescent event.
The probability of any topology of the gene genealogy can be generated from the
assumption that when $i$ lineages remain, any of the $i(i-1)/2$ possible
coalescent events is equally likely to occur.  This process for two sequences
of diploid organisms under the neutral Wright-Fisher model can be described as
follows (Fu \& Li 1999; Slatkin 1999; Hartl 2000).  Looking backward in time,
the probability of two alleles in the present generation having distinct
ancestors in the previous generation is $1-1/(2N)$.  The probability of a third
allele having an ancestor distinct from the first two is $1-2/(2N)$.  The
overall probability that $i$ distinct alleles present in any generation have
$i$ distinct ancestors in the previous generation is
$[1-1/(2N)][1-2/(2N)]\ldots [1-(i-1)/(2N)]\approx 1-(1+2+\ldots+i-1)/(2N)$=
$1-i(i-1)/(4N)$, so that the probability of the presence of a coalescence is
$i(i-1)/(4N)$.  Therefore for $i$ alleles, the probability of no coalescence
for the first $t-1$ generations followed by coalescence in the $t$th generation
is $[i(i-1)/(4N)](1-[i(i-1)/(4N)])^{t-1}$, and the mean of this geometric
distribution is $4N/[i(i-1)]$.  In a given time period the number of mutations
that have occurred on a sequence is a Poisson variable, implying that the mean
number of mutation in the two sequences is $\theta=4N\mu$, where $\mu$ is the
mutation rate per sequence per generation.  Now consider the effect of mutation
by sample size of $n=2$, for which the distribution of times until they
coalesce is a geometric distribution with mean $2N$ and $i=2$ given above.  For
two alleles to be the same state, either there is no mutation before the
coalescence or mutations have occurred in such a way that the two copies are in
the same site.  For an infinite alleles model in which every mutation destroys
genetic identity and no mutation can recover it, the probability of no mutation
occurring before coalescence at $t$ is $\exp(-2\mu t)$, where the 2 is due to
two lineages on which mutation can occur.  So the probability of identity is
obtained by averaging over the distribution of $t$,
$P=(1/2N)\int\exp(-t/2N-2\mu t)dt= 1/(1+4N\mu)$ (Hudson 1990).  Alternatively
assuming the stepwise mutation model (Ohta \& Kimura 1973), two copies of the
locus will be in the same state if the mutations on the two branches joining
them yield no net change in allele size.  Let $j_+$ and $j\_$ be the number of
mutations increase or decrease allele size by one, both with Poisson($\mu t$)
distribution because the total length of the genealogy is $2t$, but only half
of the mutations will increase or decrease allele size.  Given $t$, the
probability that $j_+=j\_$ is the probability of two draws from Poisson($\mu
t$), $P(j_+=j\_|t)=\sum_{j=0}^\infty [(\mu t)^j/j!  \exp(-\mu
t)]^2=I_0(2\sqrt{\mu t})$, where $I_0(.)$ is a modified Bessel function, thus
the total probability of identity is obtained by averaging over $t$,
$P=1/\sqrt{1+8\mu t}$.  Variations in population size will change the
distribution of coalescent times, but can be absorbed into a transformation of
time scale in the coalescent process for a population of constant size.

The original form by Kingman (1982) for a neutral locus in a large, random
mating population with constant population size has been well extended for
variable population size, population structure including island model, stepping
stone model, island-continent model, selection (Neuhauser \& Krone 1997; Krone
\& Neuhauser 1997), recombination (Griffiths \& Marjoram 1996), and conditional
coalescent.  The inference concerns the topology of the evolutionary tree, as
effect of different evolutionary forces such as mutation, recombination,
selection and migration (Tavar\'{e} et al.  1997; Wilson \& Balding 1998) as in
their programs {\bf micsat} and {\bf BATWIN}.  Computational methods involve
recursive equations or importance sampling (Griffiths \& Tavar\'{e} 1994a,b;
Felsenstein et al.  1999), MCMC (Kuhner et al.  1995, 1998), among others
(Bahlo \& Griffiths 2000; Nielsen 1997, 2000; Wiuf 2000).  Stephens \& Donnelly
(2000) suggested an improved importance sampling scheme for histories of
mutation and coalescence events.  These methods have been implemented in {\bf
genetree} (ftp://ftp.monash.edu.au), and {\bf lamarc} (Likelihood Analysis with
Metropolis Algorithm using Random Coalescence:  {\bf coalesce}, {\bf
fluctuate}, {\bf migrate}, {\bf recombine},
http://evolution.genetics.washington.edu/).  Many applications of coalescent
theory have been to samples from the control region of human mtDNA.  Since
mtDNA is haploid with recombination, DNA polymorphism is available naturally in
haplotypes.  Similar application is to non-recombining region of human Y
chromosome (Cooper et al.  1996, Wilson \& Balding 1998).  The study on the
$\beta$-globin gene tree by Harding et al.  (1997) represents a notable example
of human population study using a nuclear locus.  Again due to high mutation
rate of microsatellite marker it is less ideal for evolutionary studies.  The
relative importance of various evolutionary forces such as recombination,
natural selection, migration and population growth are not well understood.
Molecular evolution, protein and {DNA} sequence analysis are now within the
framework of bioinformatics.  See Searls (2000) for an overview, Pietro \&
Goldman (1998), Fortna \& Gardiner (2001), Whelan et al.  (2001) for
discussions of computer programs.


\section{Outline of thesis}

This thesis will focus on several scenarios of statistical power analyses.  For
linkage analysis this includes several test statistics and the use of
homozygosity mapping via computer simulation.  For association analysis this
includes model-free statistics for case-control design and tests of marker
polymorphism and mutation detection.  A closely related investigation is the
combined linkage and association under likelihood framework.  Power analysis of
both linkage using affected sib-pairs and association using TDT as in Risch and
Merikangas (1996) is also given.  Chapter 2 presents power comparison of
parametric and nonparametric linkage test statistics for small families.
Chapter 3 investigates power of model-free statistics in case-control
association design.  Chapter 4 studies effect of marker characteristics on
mutation detection.  Chapter 5 describes a simulation program for oligogenic
traits, which is compared with simulation methods with conditioning and
homozygosity mapping analyses.  Chapter 6 collects some numerical experiments
on haplotype analysis in nuclear families.  Chapter 7 examines power of TDT as
compared to other designs.  Chapter 8 is a discussion of the main results,
remaining work and some general issues.  Most chapters consist of introduction,
methods, results, discussion, and bibliographic notes.  The basic of gene
counting method and computer programs used in relevant chapters are given in
the Appendix.

\section{Bibliographic notes}

The major reference for the background materials is Thompson (1996).  Some
definitions of statistical genetics were also given by Elston (2000).  A
historical review of genetics was given by Crow (2000).  Other references
included Elandt-Johnson (1971), Morton et al.  (1983), Khoury et al.  (1993),
Weiss (1993), Pawlawitzki et al.  (1994), Lander \& Waterman (1995), Thompson
(1995), Speed \& Waterman (1996), Weir (1996), Hartl \& Clark (1997), Lange
(1997), Gillespie (1998), Sham (1998), Ott (1999) and Hartl (2000).  Other
reviews include Lander \& Schork (1994), Thompson (1995), Weeks \& Lathrop
(1995), Schork et al.  (1998), Olson et al.  (1999), Thomson \& Esposito
(1999), Morton (2000), Risch (2000), Guo \& Lange (2000).  Methods for
experimental genetics have been discussed in Doerge et al.  (1997), Darvash
(1998), Moore \& Nagle (2000).  General strategy has been discussed in Zhao et
al.  (1997).  Literature concerning other commonly used study designs, such as
migration, twin and adoption studies is not elaborated here.  A comprehensive
bibliography and list of computer programs for linkage and association anlaysis
are available via http://linkage.rockefeller.edu.

The thesis is a summary of several papers (e.g.  Sham, Lin et al.  2000,
Chapter 2; Zhao \& Sham 1997, Zhao, Curtis \& Sham 2000, Chapter 3; Sham, Zhao
\& Curtis 2000, Chapter 4; Ohadi et al.  1999, Chapter 5) and personal
communications (Dr Anthony D.  Long, Chapter 7; Dr Mark Layton, Dr Duncan
Thomas and GAW12 RFA, Chapter 5; Dr Momiao Xiong, Chapter 6; Dr Carlos Zapata,
Appendix A).  Notes elaborating MCMC linkage analysis, affected sib pair (Sham
\& Zhao 1998), QTL analysis, and a number of computer programs are available
from Section of Genetic Epidemiology and Biostatistics via
http://web1.iop.kcl.ac.uk/IoP/Departments/PsychMed/GEpiBSt/index.shtml and my 
personal web pages http://www.hgmp.mrc.ac.uk/$\sim$jzhao and 
http://www.ucl.ac.uk/$\sim$rmjdjhz.

A brief description of work other than my own is given as follows.

\begin{itemize}

\item Chapter 2.  This is a continuing work of Lin et al.  (1997) at a
referee's suggestion of looking at a fully informative marker.  The formal
definitions and distributions of statistics MLOD, MFLOD, MALOD are due to
Professor Sham and Dr Curtis.  Dr Curtis also helped to clarify 1-sided versus
2-sided of these tests.

\item Chapter 3.  The use of Equation (\ref{gendist}) for simulation is due to
professor Sham. The power calculation is a joint work with Professor Sham.

\item Chapter 4. Equation (\ref{eqn1}) is due to Professor Sham.

\item Chapter 5. Program {\bf SIM} is a joint work with Professor Sham.

\item Chapter 6.  The possibility to use haplotypes in {\bf LINKAGE} to explore
LD was suggested by Dr Curtis.  Professor Sham also suggested Equation
(\ref{gendist}) for model selection and reparametrisation of the optimisation
procedure.

\end{itemize}
